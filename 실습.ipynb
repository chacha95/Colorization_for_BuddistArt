{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "실습.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gimikk/Colorization_for_BuddistArt/blob/master/%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "SDL1okfxU4JM",
        "colab_type": "code",
        "outputId": "a776cefb-9a19-4589-e710-15d4b9b72f1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "cell_type": "code",
      "source": [
        "# pytorch 설치 명령어 입니다\n",
        "!pip3 install torch torchvision"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s3gH-zobha8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "f3bad0b8-004e-472e-ad71-6d9c1837852f"
      },
      "cell_type": "code",
      "source": [
        "# np.dot과 np.matmul 둘 다 알아두자!\n",
        "import numpy as np\n",
        "\n",
        "x = np.array([[1, 2], [3, 4]])\n",
        "y = np.array([[5, 6], [7, 8]])\n",
        "\n",
        "v = np.array([9,10])\n",
        "w = np.array([11, 12])\n",
        "\n",
        "# vector and vector\n",
        "print(np.dot(v, w))\n",
        "print(np.matmul(v, w))\n",
        "\n",
        "# vector and matrix\n",
        "print(np.dot(v, x))\n",
        "print(np.matmul(v, x))\n",
        "\n",
        "# matrix and vector\n",
        "print(np.dot(x, v))\n",
        "print(np.matmul(x, v))\n",
        "\n",
        "# matrix and matrix\n",
        "print(np.dot(x, y))\n",
        "print(np.matmul(x, y))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "219\n",
            "219\n",
            "[39 58]\n",
            "[39 58]\n",
            "[29 67]\n",
            "[29 67]\n",
            "[[19 22]\n",
            " [43 50]]\n",
            "[[19 22]\n",
            " [43 50]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pwye1IxtVYJh",
        "colab_type": "code",
        "outputId": "47019562-f579-4894-8d3e-e56968b08595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        }
      },
      "cell_type": "code",
      "source": [
        "# 수치 미분\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "# 파이썬은 파라미터로 함수도 받을 수 있다\n",
        "# f는 함수\n",
        "def numerical_diff(f, x):\n",
        "  h = 1e-4 # 0.0001 보통 많이 쓰는 h값\n",
        "  #return (f(x+h) - f(x)) / h     # 전향차분\n",
        "  return (f(x+h) - f(x-h))/ (2*h)# 중앙(중심)차분이 가장 정확함!\n",
        "\n",
        "def function1(x):\n",
        "  return 0.01*x**2 + 0.1*x\n",
        "\n",
        "# 편미분, x0, x1\n",
        "def function2(x):\n",
        "  return np.sum(x**2)\n",
        "\n",
        "# 수치적 gradient를 구하는법\n",
        "def numerical_gradient(f ,x):\n",
        "  h = 1e-4\n",
        "  grad = np.zeros_like(x) # x와 shape가 같은 array 생성\n",
        "  \n",
        "  for idx in range(x.size):\n",
        "    tmp_val = x[idx]\n",
        "    \n",
        "    x[idx] = tmp_val + h\n",
        "    fxh1 = f(x)\n",
        "    \n",
        "    x[idx] = tmp_val - h\n",
        "    fxh2 = f(x)\n",
        "    \n",
        "    grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "    x[idx] = tmp_val\n",
        "  \n",
        "  return grad\n",
        "\n",
        "x = np.arange(0.0, 20.0, 0.1)\n",
        "y = function1(x)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('f(x)')\n",
        "plt.plot(x, y)\n",
        "plt.show()\n",
        "\n",
        "print(numerical_diff(function1, 5))  # 해석적 미분값은 0.2\n",
        "print(numerical_diff(function1, 10)) # 해석적 미분값은 0.3\n",
        "\n",
        "print(numerical_diff(function2, np.array([5, 5]))) # 편미분\n",
        "\n",
        "print(numerical_gradient(function2, np.array([0.0, 2.0]))) # gradient 계산\n",
        "\n",
        "x = np.array([[1, 2], [3, 4]])\n",
        "y = np.array([[5, 6], [7, 8]])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFYCAYAAABpkTT0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f28d8cd2550>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.1999999999990898\n",
            "0.2999999999986347\n",
            "19.99999999995339\n",
            "[0. 4.]\n",
            "[[19 22]\n",
            " [43 50]]\n",
            "[[19 22]\n",
            " [43 50]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3p2oLH-XU9ft",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Linear Regression\n",
        "# numpy는 numerical python의 약자로 행렬 계산에 특화된 package\n",
        "# matplotlib는 graph를 그려주는 등의 시각화 package\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def data_generate(num_points):\n",
        "  vectors_set = []\n",
        "  for i in range(num_points):\n",
        "    x1= np.random.normal(0.0, 0.9)\n",
        "    y1= x1 * 0.8 + np.random.normal(0.0, 0.03)\n",
        "    vectors_set.append([x1, y1])\n",
        "\n",
        "  x_data = np.array([v[0] for v in vectors_set])\n",
        "  y_data = np.array([v[1] for v in vectors_set])\n",
        "  \n",
        "  return x_data, y_data\n",
        "\n",
        "# 편미분\n",
        "def function(x, w):\n",
        "  return np.sum(np.matmul(x,w))\n",
        "\n",
        "# 수치적 gradient를 구하는법\n",
        "# W 행렬을 업데이트\n",
        "def numerical_gradient(f ,X, W):\n",
        "  h = 1e-4\n",
        "  grad = np.zeros_like(W) # W와 shape가 같은 array 생성\n",
        "  \n",
        "  for idx in range(W.size):\n",
        "    tmp_val = W[idx]\n",
        "    \n",
        "    W[idx] = tmp_val + h\n",
        "    fxh1 = f(X, W)\n",
        "    \n",
        "    W[idx] = tmp_val - h\n",
        "    fxh2 = f(X, W)\n",
        "    \n",
        "    grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "    W[idx] = tmp_val\n",
        "  \n",
        "  return grad\n",
        "\n",
        "def GradientDescent(X, Y, W, lr, num_iters):\n",
        "    m = np.size(Y)\n",
        "    # X의 shape는 (100, 1)\n",
        "    # W의 shape는 (1, 1)\n",
        "    # H_x는 (100, 1)\n",
        "    # H_x = Wx로 가설을 잡은 경우\n",
        "    # bias는 뺐습니다 여러분이 추가해보세요!\n",
        "    H_x = np.matmul(X, W)\n",
        "    cost1 = Cost(W, X, Y)\n",
        "    \n",
        "    for i in range(0, num_iters):\n",
        "        # gradient를 구해준다 cost2\n",
        "        W_temp = (lr/m) * numerical_gradient(function, X, W) \n",
        "        cost2 = Cost(W - W_temp, X, Y)\n",
        "        \n",
        "        if i%10 == 0 :\n",
        "          print('cost1 :', cost1, 'cost2 :', cost2)\n",
        "        \n",
        "        # c1과 c2를 비교해 Cost가 더 작은걸 넣어준다.\n",
        "        if cost1 > cost2:\n",
        "            cost1 = cost2\n",
        "            W = W - W_temp\n",
        "    \n",
        "    return W\n",
        "\n",
        "# 수식을 참고하면서 Cost 함수를 만들어보자\n",
        "def Cost(W, X, Y):\n",
        "    m = Y.size\n",
        "    H_x = np.matmul(X, W)\n",
        "    return np.sum(np.power(np.subtract(H_x, Y), 2))/(2*m)\n",
        "\n",
        "# Hyper parameters 각자가 조절해보세요!\n",
        "# 여러 실험을 통해 좋은 결과물을 도출해보세요~\n",
        "num_points = 10000\n",
        "lr = 1e-4\n",
        "num_iters = 100\n",
        "\n",
        "# data 생성\n",
        "X, Y = data_generate(num_points)\n",
        "\n",
        "# array의 shape를 맞춰주는 작업\n",
        "m = X.size\n",
        "X = np.reshape(X, (m, 1))\n",
        "\n",
        "# np.reshape도 가능 하지만 .reshape를 통해서도 shape를 바꿀 수 있다.\n",
        "# 두가지 문법 다 알아둬야 나중에 코드 읽기 편함\n",
        "# W는 1로 초기화 해준다 -> 우리가 업데이트 해줘야할것!\n",
        "W = np.reshape(np.random.normal(0.0, 0.3), (1, 1))\n",
        "W = GradientDescent(X, Y, W, lr, num_iters)\n",
        "\n",
        "Cost(W, X, Y)\n",
        "# Y데이터를 그래프에 그려줌\n",
        "plt.scatter(np.array(X), np.array(Y), marker = 'x', color='r')\n",
        "# 함수를 그려줌, X축 Y축 값 지정\n",
        "plt.plot(np.array(X),np.array(np.matmul(X, W)))\n",
        "plt.title(\"After Regression: slope = \" + str(W))\n",
        "plt.show()\n",
        "# cost 함수 값 확인\n",
        "print(Cost(W, X, Y))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mORdoeq7U-Ps",
        "colab_type": "code",
        "outputId": "a589372b-b090-4715-bce6-e509f39e3a04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "cell_type": "code",
      "source": [
        "# Softmax classification\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Hyper-parameters\n",
        "# 이미지의 크기가 32*32 = 784차원의 벡터\n",
        "input_size = 784\n",
        "# 0~9 까지의 클래스\n",
        "num_classes = 10\n",
        "# 전체 데이터셋을 몇번 학습 시킬것인가?\n",
        "num_epochs = 5\n",
        "# 한번에 학습시킬 이미지는 몇 장인가?\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset (images and labels)\n",
        "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader (input pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)\n",
        "\n",
        "# Logistic regression model\n",
        "model = nn.Linear(input_size, num_classes)\n",
        "\n",
        "# Loss and optimizer\n",
        "# nn.CrossEntropyLoss() computes softmax internally\n",
        "criterion = nn.CrossEntropyLoss()  \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Reshape images to (batch_size, input_size)\n",
        "        images = images.reshape(-1, 28*28)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        # 이부분은 지금은 신경쓰지 말자!\n",
        "        # pytorch가 자동으로 Loss를 기반으로 weight를 업데이트 해준다!\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "# 보통 gradient를 계산하는 것은 weight 업데이트를 위해서인데 test에서는 weight를\n",
        "# 업데이트 할 필요가 없기에 gradient 계산을 하지 않는다.\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum()\n",
        "\n",
        "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 2.2451\n",
            "Epoch [1/5], Step [200/600], Loss: 2.1320\n",
            "Epoch [1/5], Step [300/600], Loss: 2.0155\n",
            "Epoch [1/5], Step [400/600], Loss: 1.9319\n",
            "Epoch [1/5], Step [500/600], Loss: 1.8657\n",
            "Epoch [1/5], Step [600/600], Loss: 1.7897\n",
            "Epoch [2/5], Step [100/600], Loss: 1.6910\n",
            "Epoch [2/5], Step [200/600], Loss: 1.6817\n",
            "Epoch [2/5], Step [300/600], Loss: 1.6056\n",
            "Epoch [2/5], Step [400/600], Loss: 1.5877\n",
            "Epoch [2/5], Step [500/600], Loss: 1.6175\n",
            "Epoch [2/5], Step [600/600], Loss: 1.4155\n",
            "Epoch [3/5], Step [100/600], Loss: 1.4522\n",
            "Epoch [3/5], Step [200/600], Loss: 1.3663\n",
            "Epoch [3/5], Step [300/600], Loss: 1.3629\n",
            "Epoch [3/5], Step [400/600], Loss: 1.3600\n",
            "Epoch [3/5], Step [500/600], Loss: 1.2777\n",
            "Epoch [3/5], Step [600/600], Loss: 1.3287\n",
            "Epoch [4/5], Step [100/600], Loss: 1.2417\n",
            "Epoch [4/5], Step [200/600], Loss: 1.1765\n",
            "Epoch [4/5], Step [300/600], Loss: 1.1360\n",
            "Epoch [4/5], Step [400/600], Loss: 1.2186\n",
            "Epoch [4/5], Step [500/600], Loss: 1.1128\n",
            "Epoch [4/5], Step [600/600], Loss: 1.1224\n",
            "Epoch [5/5], Step [100/600], Loss: 1.0338\n",
            "Epoch [5/5], Step [200/600], Loss: 1.0071\n",
            "Epoch [5/5], Step [300/600], Loss: 1.0577\n",
            "Epoch [5/5], Step [400/600], Loss: 1.1068\n",
            "Epoch [5/5], Step [500/600], Loss: 0.9593\n",
            "Epoch [5/5], Step [600/600], Loss: 0.9674\n",
            "Accuracy of the model on the 10000 test images: 82 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YkEyqOtkVDDH",
        "colab_type": "code",
        "outputId": "90ca9cd3-06e0-45e3-8fa0-46ce0dc21b81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        }
      },
      "cell_type": "code",
      "source": [
        "# Neural Network\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters(사용자가 지정해주는 파라미터)\n",
        "#input_size는 28*28 이미지 -> 784차원의 벡터로 표현 가능\n",
        "input_size = 784\n",
        "# hidden_size는 중간 hidden layer의 depth\n",
        "hidden_size = 500\n",
        "# 최종 class(10개)\n",
        "num_classes = 10\n",
        "# 몇번이나 데이터셋을 돌릴것인가? \n",
        "num_epochs = 5\n",
        "# 한번에 학습시키는데 몇장의 이미지를 넣을것인가?\n",
        "batch_size = 100\n",
        "# 코스트 함수에서의 알파값을 의미\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),  \n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        # neural net 설계\n",
        "        # nn.Linear는 fully cunnected layer를 의미한다\n",
        "        # nn.Linear의 인풋 파라미터로는 입력depth와 출력 depth\n",
        "        # 만을 입력해주면 알아서 해준다\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "        # relu 함수를 통해 다음 레이어로 feature를 전달해준다.\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
        "    \n",
        "    # 앞으로 전달\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "# Cross-Entropy을 loss로 사용\n",
        "# optimizer는 Adam이라는 optimizer로 성능이 좋아 기본으로 사용된다.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
        "\n",
        "# Train the model\n",
        "# len 함수를 통해 데이터셋의 총 갯수를 알수 있다\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    # enumerate 함수는 train_loader에서 i와 같은 카운트를 할 수 있도록 도와줌\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # Move tensors to the configured device\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # optimizer의 gradient를 초기화해준다\n",
        "        optimizer.zero_grad()\n",
        "        # backpropagation을 해준다\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "# 정확한 accuracy 측정을 위해 test셋을 이용해 test를 진행시킨다\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 0.3152\n",
            "Epoch [1/5], Step [200/600], Loss: 0.1460\n",
            "Epoch [1/5], Step [300/600], Loss: 0.2947\n",
            "Epoch [1/5], Step [400/600], Loss: 0.1806\n",
            "Epoch [1/5], Step [500/600], Loss: 0.1333\n",
            "Epoch [1/5], Step [600/600], Loss: 0.2735\n",
            "Epoch [2/5], Step [100/600], Loss: 0.2332\n",
            "Epoch [2/5], Step [200/600], Loss: 0.1389\n",
            "Epoch [2/5], Step [300/600], Loss: 0.0905\n",
            "Epoch [2/5], Step [400/600], Loss: 0.1161\n",
            "Epoch [2/5], Step [500/600], Loss: 0.1753\n",
            "Epoch [2/5], Step [600/600], Loss: 0.0467\n",
            "Epoch [3/5], Step [100/600], Loss: 0.0737\n",
            "Epoch [3/5], Step [200/600], Loss: 0.0900\n",
            "Epoch [3/5], Step [300/600], Loss: 0.0348\n",
            "Epoch [3/5], Step [400/600], Loss: 0.0464\n",
            "Epoch [3/5], Step [500/600], Loss: 0.0709\n",
            "Epoch [3/5], Step [600/600], Loss: 0.0492\n",
            "Epoch [4/5], Step [100/600], Loss: 0.0489\n",
            "Epoch [4/5], Step [200/600], Loss: 0.0574\n",
            "Epoch [4/5], Step [300/600], Loss: 0.0329\n",
            "Epoch [4/5], Step [400/600], Loss: 0.0758\n",
            "Epoch [4/5], Step [500/600], Loss: 0.0162\n",
            "Epoch [4/5], Step [600/600], Loss: 0.0458\n",
            "Epoch [5/5], Step [100/600], Loss: 0.0288\n",
            "Epoch [5/5], Step [200/600], Loss: 0.0254\n",
            "Epoch [5/5], Step [300/600], Loss: 0.0178\n",
            "Epoch [5/5], Step [400/600], Loss: 0.0552\n",
            "Epoch [5/5], Step [500/600], Loss: 0.0196\n",
            "Epoch [5/5], Step [600/600], Loss: 0.0594\n",
            "Accuracy of the network on the 10000 test images: 97.96 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ot6YuoMFVDNc",
        "colab_type": "code",
        "outputId": "e7cd46ab-593d-4683-c2fc-b29ccf251a64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        }
      },
      "cell_type": "code",
      "source": [
        "# CNN \n",
        "# 스스로 코드를 분석해보세요!\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper parameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)\n",
        "\n",
        "# Convolutional neural network (two convolutional layers)\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        # nn.Sequential 모듈을 이용해 간단하게 표현해 줄 수 있다\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(7*7*32, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "model = ConvNet(num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "# Test the model\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 0.2512\n",
            "Epoch [1/5], Step [200/600], Loss: 0.1171\n",
            "Epoch [1/5], Step [300/600], Loss: 0.0788\n",
            "Epoch [1/5], Step [400/600], Loss: 0.0769\n",
            "Epoch [1/5], Step [500/600], Loss: 0.0181\n",
            "Epoch [1/5], Step [600/600], Loss: 0.0281\n",
            "Epoch [2/5], Step [100/600], Loss: 0.0779\n",
            "Epoch [2/5], Step [200/600], Loss: 0.0299\n",
            "Epoch [2/5], Step [300/600], Loss: 0.0539\n",
            "Epoch [2/5], Step [400/600], Loss: 0.0143\n",
            "Epoch [2/5], Step [500/600], Loss: 0.0116\n",
            "Epoch [2/5], Step [600/600], Loss: 0.0337\n",
            "Epoch [3/5], Step [100/600], Loss: 0.0334\n",
            "Epoch [3/5], Step [200/600], Loss: 0.0297\n",
            "Epoch [3/5], Step [300/600], Loss: 0.0156\n",
            "Epoch [3/5], Step [400/600], Loss: 0.0257\n",
            "Epoch [3/5], Step [500/600], Loss: 0.0255\n",
            "Epoch [3/5], Step [600/600], Loss: 0.0133\n",
            "Epoch [4/5], Step [100/600], Loss: 0.0249\n",
            "Epoch [4/5], Step [200/600], Loss: 0.0029\n",
            "Epoch [4/5], Step [300/600], Loss: 0.0267\n",
            "Epoch [4/5], Step [400/600], Loss: 0.0207\n",
            "Epoch [4/5], Step [500/600], Loss: 0.0674\n",
            "Epoch [4/5], Step [600/600], Loss: 0.0192\n",
            "Epoch [5/5], Step [100/600], Loss: 0.0097\n",
            "Epoch [5/5], Step [200/600], Loss: 0.0022\n",
            "Epoch [5/5], Step [300/600], Loss: 0.0173\n",
            "Epoch [5/5], Step [400/600], Loss: 0.0506\n",
            "Epoch [5/5], Step [500/600], Loss: 0.0401\n",
            "Epoch [5/5], Step [600/600], Loss: 0.0032\n",
            "Test Accuracy of the model on the 10000 test images: 98.97 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ybzgg8GJIAYj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GAN 코드 스스로 분석해보기\n",
        "# 모르는게 있으면 구글링을 해보세요!\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "latent_size = 64\n",
        "hidden_size = 256\n",
        "image_size = 784\n",
        "num_epochs = 200\n",
        "batch_size = 100\n",
        "sample_dir = 'samples'\n",
        "\n",
        "# Create a directory if not exists\n",
        "if not os.path.exists(sample_dir):\n",
        "    os.makedirs(sample_dir)\n",
        "\n",
        "# Image processing\n",
        "transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=(0.5, 0.5, 0.5),   # 3 for RGB channels\n",
        "                                     std=(0.5, 0.5, 0.5))])\n",
        "\n",
        "# MNIST dataset\n",
        "mnist = torchvision.datasets.MNIST(root='../../data/',\n",
        "                                   train=True,\n",
        "                                   transform=transform,\n",
        "                                   download=True)\n",
        "\n",
        "# Data loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=True)\n",
        "\n",
        "# Discriminator\n",
        "D = nn.Sequential(\n",
        "    nn.Linear(image_size, hidden_size),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(hidden_size, hidden_size),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(hidden_size, 1),\n",
        "    nn.Sigmoid())\n",
        "\n",
        "# Generator \n",
        "G = nn.Sequential(\n",
        "    nn.Linear(latent_size, hidden_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_size, hidden_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_size, image_size),\n",
        "    nn.Tanh())\n",
        "\n",
        "# Device setting\n",
        "D = D.to(device)\n",
        "G = G.to(device)\n",
        "\n",
        "# Binary cross entropy loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\n",
        "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)\n",
        "\n",
        "def denorm(x):\n",
        "    out = (x + 1) / 2\n",
        "    return out.clamp(0, 1)\n",
        "\n",
        "def reset_grad():\n",
        "    d_optimizer.zero_grad()\n",
        "    g_optimizer.zero_grad()\n",
        "\n",
        "# Start training\n",
        "total_step = len(data_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, _) in enumerate(data_loader):\n",
        "        images = images.reshape(batch_size, -1).to(device)\n",
        "        \n",
        "        # Create the labels which are later used as input for the BCE loss\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "        # ================================================================== #\n",
        "        #                      Train the discriminator                       #\n",
        "        # ================================================================== #\n",
        "\n",
        "        # Compute BCE_Loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n",
        "        # Second term of the loss is always zero since real_labels == 1\n",
        "        outputs = D(images)\n",
        "        d_loss_real = criterion(outputs, real_labels)\n",
        "        real_score = outputs\n",
        "        \n",
        "        # Compute BCELoss using fake images\n",
        "        # First term of the loss is always zero since fake_labels == 0\n",
        "        z = torch.randn(batch_size, latent_size).to(device)\n",
        "        fake_images = G(z)\n",
        "        outputs = D(fake_images)\n",
        "        d_loss_fake = criterion(outputs, fake_labels)\n",
        "        fake_score = outputs\n",
        "        \n",
        "        # Backprop and optimize\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        reset_grad()\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "        \n",
        "        # ================================================================== #\n",
        "        #                        Train the generator                         #\n",
        "        # ================================================================== #\n",
        "\n",
        "        # Compute loss with fake images\n",
        "        z = torch.randn(batch_size, latent_size).to(device)\n",
        "        fake_images = G(z)\n",
        "        outputs = D(fake_images)\n",
        "        \n",
        "        # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n",
        "        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "        \n",
        "        # Backprop and optimize\n",
        "        reset_grad()\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "        \n",
        "        if (i+1) % 200 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
        "                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n",
        "                          real_score.mean().item(), fake_score.mean().item()))\n",
        "    \n",
        "    # Save real images\n",
        "    if (epoch+1) == 1:\n",
        "        images = images.reshape(images.size(0), 1, 28, 28)\n",
        "        save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'))\n",
        "    \n",
        "    # Save sampled images\n",
        "    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
        "    save_image(denorm(fake_images), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}